{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "class AdaptiveNeaurons(object):\n",
    "    \n",
    "    def __init__(self, eta, n_iter):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Initialize theta \n",
    "        initial_theta = np.zeros((X.shape[1], 1))\n",
    "        \n",
    "        # Compute linear activation\n",
    "        J_cost = self.activation(X, y, initial_theta)\n",
    "        \n",
    "        # Short hand for cost function to be minimized\n",
    "        def costFunc(theta):\n",
    "            return self.activation(X, y, theta, True)\n",
    "\n",
    "        # Gradient descent \n",
    "        results = minimize(costFunc, x0=initial_theta, options={'disp': True, 'maxiter':self.n_iter}, method=\"L-BFGS-B\", jac=True)\n",
    "        theta = results[\"x\"]\n",
    "        return theta\n",
    "        \n",
    "    \n",
    "    def activation(self, X, y, theta, return_grad=False):\n",
    "        # Number of training examples\n",
    "        m = len(X)\n",
    "    \n",
    "        theta = np.reshape(theta, (-1,y.shape[1]))\n",
    "        \n",
    "        # Return these values         \n",
    "        J = 0\n",
    "        grad = np.zeros(theta.shape)\n",
    "        \n",
    "        # Cost function         \n",
    "        J = (1./(2*m)) * np.power((np.dot(X, theta) - y), 2).sum() \n",
    "        \n",
    "        # Gradient descent         \n",
    "        grad = (1./m) * np.dot(X.T, np.dot(X, theta) - y)\n",
    "        \n",
    "        if return_grad == True:\n",
    "            return J, grad.flatten()\n",
    "        elif return_grad == False:\n",
    "            return J\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f72a51245d0>]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the training dataset\n",
    "data = np.loadtxt('ex1data1.txt', delimiter=',')\n",
    "df = pd.DataFrame(data=data, columns= ['feature','target'])\n",
    "\n",
    "X = df.iloc[:, 0]\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "# split data into training and testing dataset ( might avoid overfitting )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# number of training examples\n",
    "m_train = X_train.size\n",
    "m_test = X_test.size\n",
    "\n",
    "y_train = np.reshape(y_train, (m_train, 1))\n",
    "y_test = np.reshape(y_test, (m_test, 1))\n",
    "\n",
    "# Visualize training set \n",
    "plt.plot(X_train, y_train, 'rx')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.8852       5.02328859]\n",
      " [  3.5129       2.82202867]\n",
      " [  0.47953      3.24078042]\n",
      " [  3.9115       4.62141619]\n",
      " [  0.152        2.99082226]\n",
      " [ 13.501       11.73887912]\n",
      " [  9.0551      12.41644771]\n",
      " [  2.4406       3.29405215]\n",
      " [ 20.992       20.73282395]\n",
      " [  6.8233       3.39712398]\n",
      " [  4.9981       5.48405917]\n",
      " [  1.0179       3.01620115]\n",
      " [ 21.767       20.6478286 ]\n",
      " [  5.3436       4.18255287]\n",
      " [ 11.854        4.76590829]\n",
      " [  4.2415       6.5783444 ]\n",
      " [ -1.22         2.66999473]\n",
      " [ 17.929       21.8557203 ]\n",
      " [  5.3854      10.39810737]\n",
      " [  1.844        3.32721231]\n",
      " [  1.8396       2.73619533]\n",
      " [  3.3411       5.03250639]\n",
      " [  3.0825       3.04409399]\n",
      " [  6.5987       4.14699847]\n",
      " [  0.56077      2.52358724]\n",
      " [  5.1694       6.94729606]\n",
      " [ 17.592        3.69676253]\n",
      " [  0.92695      3.56735411]\n",
      " [  4.6042       3.13363839]\n",
      " [  4.263        2.95454959]\n",
      " [ -0.74279      2.58248543]\n",
      " [ 12.054       14.22888381]\n",
      " [ 12.           6.65124886]\n",
      " [  1.9869       2.73344196]\n",
      " [  7.2258       6.448098  ]\n",
      " [  1.0173       2.96568279]\n",
      " [  0.67861      3.99077462]\n",
      " [  0.71618      3.13483551]\n",
      " [ 24.147       22.961857  ]\n",
      " [ 14.692       12.15547606]\n",
      " [ 15.505       13.33822829]\n",
      " [  3.6518       4.07924161]\n",
      " [  3.1386       3.79133482]\n",
      " [  6.7504       5.40876047]\n",
      " [ 22.638       19.06164773]\n",
      " [  4.3483       5.33238436]\n",
      " [  4.0259       5.16251337]\n",
      " [  3.8845       5.40684508]\n",
      " [  9.1302       2.99956122]\n",
      " [  5.3048       4.00238666]\n",
      " [ 17.054       19.07840737]\n",
      " [  2.0576       2.49677181]\n",
      " [ 11.886        6.4175715 ]\n",
      " [  0.29678      4.22086063]\n",
      " [  3.8166       2.43320486]\n",
      " [  1.2784       3.57238201]\n",
      " [  3.1551       3.24652658]\n",
      " [  3.3928       3.09365466]]\n"
     ]
    }
   ],
   "source": [
    "ann = AdaptiveNeaurons(eta=0.01, n_iter=10)\n",
    "\n",
    "X_train_padded = np.column_stack((np.ones((m_train, 1)), X_train))\n",
    "X_test_padded = np.column_stack((np.ones((m_test, 1)), X_test))\n",
    "\n",
    "ann.fit(X_train_padded, y_train)\n",
    "\n",
    "# Store the predicted dependent variable\n",
    "y_pred = ann.predict(X_train_padded)\n",
    "print(np.column_stack((y_train, y_pred)))\n",
    "# plt.plot(X_train, y_train, 'rx')\n",
    "# plt.plot(X_test, y_pred,'-', label='Linear regression')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
