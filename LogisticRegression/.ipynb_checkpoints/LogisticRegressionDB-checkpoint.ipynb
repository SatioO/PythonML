{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros): 0.693147\n",
      "Gradient at initial theta (zeros):\n",
      "[[ -0.1        -12.00921659 -11.26284221]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203498\n",
      "         Iterations: 157\n",
      "         Function evaluations: 287\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203498\n",
      "         Iterations: 1\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "Cost at theta found by fmin: 0.206231\n",
      "theta:\n",
      "-25.1613006241\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import fmin\n",
    "from scipy.optimize import fmin_bfgs\n",
    "# load training data to build model\n",
    "data = np.loadtxt('ex2data1.txt', delimiter=',')\n",
    "\n",
    "# using simoid function \n",
    "def sigmoid(z):\n",
    "    return expit(z)\n",
    "\n",
    "# compute cost and gradient \n",
    "def costFunction(theta, X, y, return_grad=False):\n",
    "    m = len(y) \n",
    "    one = y * np.transpose(np.log( sigmoid( np.dot(X,theta) ) ))\n",
    "    two = (1-y) * np.transpose(np.log( 1 - sigmoid( np.dot(X,theta) ) ))\n",
    "    J = -(1./m)*(one+two).sum()\n",
    "    \n",
    "    grad = (1./m) * np.dot(sigmoid( np.dot(X,theta) ).T - y, X).T\n",
    "\n",
    "    if return_grad == True:\n",
    "        return J, np.transpose(grad)\n",
    "    elif return_grad == False:\n",
    "        return J # for use in fmin/fmin_bfgs optimization function\n",
    "\n",
    "# fit data into the data set\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "\n",
    "# Size of a training set \n",
    "m, n = X.shape\n",
    "\n",
    "# X subscript 0 to 1\n",
    "X_padded = np.column_stack((np.ones((m, 1)), X))\n",
    "\n",
    "# Set initail value of theta\n",
    "initial_theta = np.zeros(shape=(n + 1, 1))\n",
    "\n",
    "cost, grad = costFunction(initial_theta, X_padded, y, return_grad=True)\n",
    "\n",
    "print('Cost at initial theta (zeros): {:f}'.format(cost))\n",
    "print('Gradient at initial theta (zeros):')\n",
    "print(grad)\n",
    "\n",
    "# Optimizing using fmin (and fmin_bfgs)\n",
    "myargs=(X_padded, y)\n",
    "theta = fmin(costFunction, x0=initial_theta, args=myargs)\n",
    "theta, cost_at_theta, _, _, _, _, _ = fmin_bfgs(costFunction, x0=theta, args=myargs, full_output=True)\n",
    "# Print theta to screen\n",
    "print('Cost at theta found by fmin: {:f}'.format(cost_at_theta))\n",
    "print('theta:'),\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
